{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Name: Aidan Keeshan\n",
    "### Student ID: 18200117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All necessary imports are provided. Please do not add further imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the exact same data you used for the regression in E-tivity 3, but this time you know exactly what function generated the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(X):\n",
    "    #return: 0.5X^5-0.5X^3-4.25X^2+5.125X-0.4375\n",
    "    return 0.5*((X-.5)-10*(X-.5)**2-(X-.5)**3+X**5)+1\n",
    "\n",
    "points = 100\n",
    "X = np.linspace(0, 1, points) # 100 values between 0 and 100\n",
    "noise=np.random.random(points)/4\n",
    "y_nf = target(X) #noise free target\n",
    "y = y_nf+noise #noisy target\n",
    "\n",
    "plt.plot(X,y,'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an implementation of linear regression with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_reg(X,y,l):\n",
    "    n = len(X)\n",
    "    m=X.T.dot(X)\n",
    "    return np.linalg.inv(m+l*np.identity(m.shape[0])).dot(X.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lin_reg(w,X):\n",
    "    # Calculation of outputs given weights and data (X). Note that X needs to contain the bias of 1. \n",
    "    out=[]\n",
    "    for x in X:\n",
    "        out.append(w.T.dot(x))\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_error(w,X,y):\n",
    "    # Calculate the error as the mean squared error\n",
    "    pred = lin_reg(w,X)\n",
    "    return math.sqrt((pred-np.array(y)).dot(pred-np.array(y))/len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create higher order features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transPoly(X, power):\n",
    "    # Extend the data in X with a bias (1) and powers of the feature up to 'power'\n",
    "    ones = np.ones((X.shape[0],1))\n",
    "    extra=[]\n",
    "    for x in X:\n",
    "        row=[]\n",
    "        for p in range(2,power+1):\n",
    "            row.append(x**p)\n",
    "        extra.append(row)\n",
    "    return np.concatenate((ones, X.reshape(len(X),1),np.array(extra)),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over lambda, train the model and calculate Eout. Plot the latter versus lambda to see how much regularization is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ein=[]\n",
    "eout=[]\n",
    "weights=[]\n",
    "lambdas = ...\n",
    "X_trans = transPoly(X,50)\n",
    "# random_state fixed to get reproducible (and 'good'! :-)) results\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trans, y, train_size=0.9, random_state =5)\n",
    "for l in lambdas:    \n",
    "    w = weights_reg(X_train,y_train,l)\n",
    "    ein.append(calc_error(w,X_train,y_train))\n",
    "    eout.append(calc_error(w,X_test,y_test))\n",
    "    weights.append(w)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
